---
title: 'Creating Judges'
description: 'Set up quality metrics for your router'
---
## Understanding Judges
Judges are the foundation of Martian's quality optimization system. They:
- Define what "good" means for your specific use case
- Automatically evaluate model outputs
- Guide router decisions for model selection
- Enable continuous quality improvement
<CardGroup cols={2}>
  <Card title="Quality Definition" icon="scale-balanced">
    Define custom quality metrics specific to your translation needs
  </Card>
  <Card title="Automatic Evaluation" icon="robot">
    Automatically score translations based on your criteria
  </Card>
</CardGroup>
## Creating a Translation Judge
Let's create a judge for Korean-English translation:

Start by creating a `create_judge.py` file.

With the following script you can change rubric, possible scores range, and also you can set generate_validation_plan to True to get more advanced judge.

```python create_judge.py

from config import API_URL, ORG_ID, HEADERS
import requests

url = f'{API_URL}/org/{ORG_ID}/judges'
data = {
    "name": "Translation Judge",
    "description": "A test judge for translation quality",
    "structure": "RubricNumericalJudge",
    "parameters": {
        "min_score": {"value": 0, "frozen": False},
        "max_score": {"value": 1, "frozen": False},
        "rubric": {"value": "Determine whether the translation is accurate and faithful to the original text.", "frozen": False},
        "judgeLLM": {"value": "openai/openai/gpt-4o-mini", "frozen": False},
    },
    "generate_validation_plan": False,
}
response = requests.post(url, headers=HEADERS, json=data)
print(response.json())

```

## Adding data to a judge

Start by creating a `add_data_to_judge_good.py` file and a `add_data_to_judge_bad.py`.

With the following scripts you can change pass Request and Response data for judge validation, we provide you with examples that show you both positive and negative score.

```python add_data_to_judge_good.py
import requests
from config import API_URL, ORG_ID, HEADERS, client

judge_id = input("Enter judge ID: ")
version_id = input("Enter version ID: ")

request = {
    "model": "gpt-4o-mini-2024-07-18",
    "messages": [
        {"role": "system", "content": """You are a highly skilled translator
             with expertise in many languages. Your task is to:
            - Identify if the input is Korean or English
            - If Korean, translate to English
            - If English, translate to Korean
            - Preserve meaning, tone, and nuance
            - Maintain proper grammar and formality level
            - output ONLY the translation
            """},
        {"role": "user", "content": "<translate>apple</translate>"}
    ],
}

response = client.chat.completions.create(
    model="gpt-4o-mini-2024-07-18",
    messages=[
        {"role": "system", "content": """You are a highly skilled translator with expertise in many languages. Your task is to:
            - Identify if the input is Korean or English
            - If Korean, translate to English
            - If English, translate to Korean
            - Preserve meaning, tone, and nuance
            - Maintain proper grammar and formality level
            - output ONLY the translation
            """},
        {"role": "user", "content": "<translate>apple</translate>"}
    ],
)

print(response)

# Convert the ChatCompletion object to a dictionary
response_dict = {
    'id': response.id,
    'choices': [
        {
            'message': {
                'role': choice.message.role,
                'content': choice.message.content
            },
            'index': choice.index,
            'finish_reason': choice.finish_reason
        }
        for choice in response.choices
    ],
    'model': response.model,
    'created': response.created,
    'usage': {
        'prompt_tokens': response.usage.prompt_tokens,
        'completion_tokens': response.usage.completion_tokens,
        'total_tokens': response.usage.total_tokens
    },
    'object': response.object,
    'cost': response.cost,
    'response': {
        'role': response.choices[0].message.role,
        'content': response.choices[0].message.content
    }
}

# Store response
url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}/versions/{version_id}/response'

data = {
    'request': request,
    'response': response_dict
}

response = requests.post(url, headers=HEADERS, json=data)
print(response.json()) 
```

and for negative scores

```python add_data_to_judge_bad.py
import requests
from config import API_URL, ORG_ID, HEADERS, client

judge_id = input("Enter judge ID: ")
version_id = input("Enter version ID: ")

request = {
    "model": "gpt-4o-mini-2024-07-18",
    "messages": [
        {"role": "system", "content": """You are a highly skilled translator with expertise in many languages. Your task is to:
            - Identify if the input is Korean or English
            - If Korean, translate to English
            - If English, translate to Korean
            - Preserve meaning, tone, and nuance
            - Maintain proper grammar and formality level
            """},
        {"role": "user", "content": "Tell me a joke?"}
    ],
}

response = client.chat.completions.create(
    model="gpt-4o-mini-2024-07-18",
    messages=[
        {"role": "system", "content": """You are a highly skilled translator with expertise in many languages. Your task is to:
            - Identify if the input is Korean or English
            - If Korean, translate to English
            - If English, translate to Korean
            - Preserve meaning, tone, and nuance
            - Maintain proper grammar and formality level
            """},
        {"role": "user", "content": "Tell me a joke?"}
    ],
)

response.choices[0].message.content = "Ni≈°ta ne radim."

print(response)

# Convert the ChatCompletion object to a dictionary
response_dict = {
    'id': response.id,
    'choices': [
        {
            'message': {
                'role': choice.message.role,
                'content': choice.message.content
            },
            'index': choice.index,
            'finish_reason': choice.finish_reason
        }
        for choice in response.choices
    ],
    'model': response.model,
    'created': response.created,
    'usage': {
        'prompt_tokens': response.usage.prompt_tokens,
        'completion_tokens': response.usage.completion_tokens,
        'total_tokens': response.usage.total_tokens
    },
    'object': response.object,
    'cost': response.cost,
    'response': {
        'role': response.choices[0].message.role,
        'content': response.choices[0].message.content
    }
}

# Store response
url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}/versions/{version_id}/response'

data = {
    'request': request,
    'response': response_dict
}

response = requests.post(url, headers=HEADERS, json=data)
print(response.json())
```

## Run the judge 

Now we are ready to get evaluations from the judge. After you create a script called `run_judge.py` go ahead and run the code below in that script.

```python run_judge.py
from config import API_URL, ORG_ID, HEADERS
import requests

def test_judge(judge_id, version_id, request_response_id):
    url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}/versions/{version_id}/call'
    
    # Example translation pair
    test_data = {
        'request_response_id': request_response_id,
    }
    
    response = requests.post(url, headers=HEADERS, json=test_data)
    result = response.json()
    print(result)


judge_id = input("Enter judge ID: ")
version_id = input("Enter version ID: ")
request_response_id = input("Enter request response ID: ")
test_judge(judge_id, version_id, request_response_id)
```

## Pass judgements to the judge

Start by creating a `add_judgement.py` file.

With the following script you can close the feedback loop and send judgements to the judge.

```python add_judgement.py
import requests
from config import API_URL, ORG_ID, HEADERS, client

judge_id = input("Enter judge ID: ")
version_id = input("Enter version ID: ")
request_response_id = input("Enter request_response_id: ")

judgement = {"score": 1, "rationale": "Very useful"}

url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}/versions/{version_id}/judgement'

data = {
    'request_response_id': request_response_id,
    'judgement': judgement
}

response = requests.post(url, headers=HEADERS, json=data)
print(response.json())
```

## Creating a new router using your judge

Once you feel confident with your judge you can create a new router with this judge. To update an existing router with your judge (see the next section).

Start by creating a `create_router_for_judge.py` file and add the following code.

```python create_router_for_judge.py
from config import API_URL, ORG_ID, HEADERS
import requests

judge_id = input("Enter judge ID: ")
judge_version_id = input("Enter judge version ID: ")

url = f'{API_URL}/org/{ORG_ID}/routers'

data = {
    'name': 'translation-router',
    'description': 'Routes Korean-English translation requests based on quality needs',
    'baseline_model': 'gpt-4o-mini',  # The model you currently use for the application
    'judge_id': judge_id,
    'judge_version_id': judge_version_id,
}

response = requests.post(url, headers=HEADERS, json=data)
print(response.json())
router_id = response.json()['router_id']
print(f"Created translation router with ID: {router_id}")
```

## Update existing router with judge

Start by creating a `update_router.py` file.

With the following script you can update an existing router to use the judge you created.

```python update_router.py
from config import API_URL, ORG_ID, HEADERS
import requests

router_id = input("Enter router ID: ")
router_version_id = input("Enter router version ID: ")
judge_id = input("Enter judge ID: ")
judge_version_id = input("Enter judge version ID: ")

url = f'{API_URL}/org/{ORG_ID}/routers/{router_id}/versions/{router_version_id}'

data = {
    'judge_id': judge_id,
    'judge_version_id': judge_version_id
}

response = requests.post(url, headers=HEADERS, json=data)
print(response.json())
router_id = response.json()['router_id']
print(f"Updated router with ID: {router_id}")
```


## Judge Versions
Like routers, judges have versions that improve over time. Each version represents a refinement in how quality is evaluated.
```python judge.py
def manage_judge_versions(judge_id):
    """List and manage judge versions."""
    # Get all versions
    url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}/versions'
    response = requests.get(url, headers=HEADERS)
    versions = response.json()['versions']
    
    print("Judge Versions:")
    for version in versions:
        print(f"\nVersion ID: {version['version_id']}")
        print(f"Created: {version['created_at']}")
        print(f"Slug: {version['slug']}")
        print(f"IAA Score: {version['iaa']}")
        
    return versions
def get_version_details(judge_id, version_id):
    """Get detailed information about a specific version."""
    url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}/versions/{version_id}'
    response = requests.get(url, headers=HEADERS)
    version = response.json()
    
    print(f"\nVersion Details:")
    print(f"Created: {version['created_at']}")
    print(f"IAA Score: {version['iaa']}")
    return version
```
<Note>
  The IAA (Inter-Annotator Agreement) score indicates how consistently a judge version evaluates similar translations.
</Note>
## Using Judges with Routers
Judges are automatically connected to routers during router creation. Here's how to use them together:
```python judge.py
def create_router_with_judge(judge_id):
    """Create a router that uses a specific judge."""
    url = f'{API_URL}/org/{ORG_ID}/routers'
    data = {
        'name': 'korean-english-router',
        'description': 'Routes Korean-English translation requests',
        'judge_id': judge_id,
        'baseline_model': 'gpt-4'
    }
    response = requests.post(url, headers=HEADERS, json=data)
    router_id = response.json()['router_id']
    return router_id
def store_translation_feedback(router_id, version_id, request, response):
    """Store a translation pair for judge evaluation."""
    url = f'{API_URL}/org/{ORG_ID}/routers/{router_id}/versions/{version_id}/response'
    data = {
        'request': request,
        'response': response
    }
    response = requests.post(url, headers=HEADERS, json=data)
    return response.json()['request_response_id']
```
## Translation Quality Metrics
Judges evaluate translations based on multiple criteria:
<AccordionGroup>
  <Accordion title="Accuracy">
    - Meaning preservation
    - Cultural nuance
    - Context awareness
  </Accordion>
  <Accordion title="Fluency">
    - Natural language flow
    - Grammar correctness
    - Idiomatic usage
  </Accordion>
  <Accordion title="Style">
    - Tone consistency
    - Formality level
    - Target audience appropriateness
  </Accordion>
</AccordionGroup>
### Monitoring Performance
Track judge and router performance together:
```python judge.py
def monitor_translation_quality(router_id, version_id, time_period='7d'):
    """Monitor translation quality metrics."""
    url = f'{API_URL}/org/{ORG_ID}/routers/{router_id}/versions/{version_id}/metrics'
    params = {'period': time_period}
    response = requests.get(url, headers=HEADERS, params=params)
    metrics = response.json()
    
    print("\nQuality Metrics:")
    print(f"Average Score: {metrics['average_score']:.2f}")
    print(f"Score Distribution:")
    for range_key, count in metrics['score_distribution'].items():
        print(f"  {range_key}: {count} translations")
        
    return metrics
```
## Best Practices
1. Test judge behavior with known good/bad translations
2. Monitor IAA scores across versions
3. Regularly review judge evaluations
4. Calibrate quality thresholds based on business needs
## Troubleshooting
<AccordionGroup>
  <Accordion title="Inconsistent Scores">
    Check IAA scores and review recent evaluations
  </Accordion>
  <Accordion title="Low Quality Scores">
    Review quality criteria and judge version
  </Accordion>
  <Accordion title="Integration Issues">
    Verify judge ID and version compatibility
  </Accordion>
</AccordionGroup>

<Note>
  Remember to periodically review judge versions to ensure they align with your current quality standards.
</Note>
---
title: 'Initial Application'
description: 'Start with a basic LLM application'
---

Let's start with a simple translation application. We'll then show how easy it is to optimize it using Martian's routing system.

## Basic Translation App
Here's our starting application:

```python basic_translator.py
from openai import OpenAI
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def translate(text):
    """Translate text between Korean and English."""
    response = client.chat.completions.create(
        model="gpt-4o-mini",  # Fixed model for all translations
        messages=[
            {"role": "system", "content": """You are a highly skilled translator with expertise in many languages. Your task is to:
                - Identify if the input is Korean or English
                - If Korean, translate to English
                - If English, translate to Korean
                - Preserve meaning, tone, and nuance
                - Maintain proper grammar and formality level
                """},
            {"role": "user", "content": text}
        ]
    )
    return response.choices[0].message.content.strip()

if __name__ == "__main__":
    while True:
        text = input("\nEnter text to translate (or 'q' to quit): ")
        if text.lower() == 'q':
            break
            
        result = translate(text)
        print(f"\nTranslation: {result}")
```

## Current Limitations from Using OpenAI Instead of Martian
This basic implementation works but has some drawbacks:

<CardGroup cols={2}>
  <Card title="Fixed Model" icon="lock">
    Always uses GPT-4o-Mini, even for simple translations
  </Card>
  <Card title="Cost Inefficient" icon="money-bill">
    No way to optimize for cost vs quality
  </Card>
  <Card title="No Quality Metrics" icon="chart-line">
    Can't track or improve translation quality
  </Card>
  <Card title="No Feedback Loop" icon="rotate">
    Doesn't learn from past translations
  </Card>
</CardGroup>

In the following sections, we'll modify this application to use Martian's router system, which will help us:
- Route requests to appropriate models based on needs
- Optimize for cost and quality
- Collect and use quality feedback
- Monitor and improve translation performance

Let's get started by setting up our Martian environment...
---
title: 'Providing Feedback'
description: 'Help your router learn and improve automatically'
---

## Understanding Feedback
The system improves through:
<CardGroup cols={2}>
  <Card title="Direct Judgements" icon="star">
    - Immediate quality scoring
    - Guide future routing decisions
    - Help identify optimal models
  </Card>
  <Card title="Request/Response Storage" icon="database">
    - Builds interaction history
    - Provides training data
    - Enables performance analysis
  </Card>
</CardGroup>

## Implementation
Add feedback functionality to your translator:

````python basic_translator.py
from config import client, API_URL, ORG_ID, HEADERS
import requests
from typing import Dict, List, Any, Optional
from datetime import datetime

def translate(text: str, router_name: str = "translation-router") -> str:
    """Translate text between Korean and English with automatic model selection."""
    response = client.chat.completions.create(
        model=router_name,
        messages=[
            {"role": "system", "content": "You are a skilled Korean-English translator."},
            {"role": "user", "content": text}
        ]
    )
    return response.choices[0].message.content.strip()

def provide_direct_feedback(
    text: str,
    translation: str,
    score: float,
    rationale: str
) -> str:
    """
    Provide immediate feedback on translation quality.
    
    Args:
        text: Original text to translate
        translation: The translation to evaluate
        score: Quality score (0-1)
        rationale: Explanation of the score
    
    Returns:
        judgement_id: Unique identifier for the feedback
    """
    url = f"{API_URL}/org/{ORG_ID}/judgement"
    
    feedback_data = {
        'request': {
            'messages': [
                {'role': 'user', 'content': text}
            ]
        },
        'response': {
            'choices': [{
                'message': {
                    'content': translation
                }
            }]
        },
        'score': score,
        'rationale': rationale
    }
    
    response = requests.post(url, headers=HEADERS, json=feedback_data)
    return response.json()['judgement_id']

def store_translation_pair(
    text: str,
    translation: str,
    router_id: Optional[str] = None,
    version_id: Optional[str] = None
) -> str:
    """
    Store a request/response pair for future analysis.
    
    Args:
        text: Original text
        translation: Generated translation
        router_id: Optional router identifier
        version_id: Optional version identifier
    
    Returns:
        request_response_id: Unique identifier for the stored pair
    """
    url = f"{API_URL}/org/{ORG_ID}/response"
    if router_id and version_id:
        url = f"{API_URL}/org/{ORG_ID}/routers/{router_id}/versions/{version_id}/response"
    
    data = {
        'request': {
            'messages': [
                {'role': 'user', 'content': text}
            ]
        },
        'response': {
            'choices': [{
                'message': {
                    'content': translation
                }
            }]
        }
    }
    
    response = requests.post(url, headers=HEADERS, json=data)
    return response.json()['request_response_id']

# Example usage
if __name__ == "__main__":
    # Translate text
    text = "안녕하세요"
    translation = translate(text)
    
    # Provide direct feedback
    judgement_id = provide_direct_feedback(
        text=text,
        translation=translation,
        score=0.95,
        rationale="Accurate and natural translation"
    )
    print(f"Recorded feedback with ID: {judgement_id}")
    
    # Store for later analysis
    pair_id = store_translation_pair(text, translation)
    print(f"Stored translation pair with ID: {pair_id}")
````

## Understanding Response Formats

<AccordionGroup>
  <Accordion title="Direct Feedback Response">
    ```json
    {
        "judgement_id": "judge_abc123...",
        "score": 0.95,
        "rationale": "Accurate and natural translation"
    }
    ```
  </Accordion>
  <Accordion title="Stored Pair Response">
    ```json
    {
        "request_response_id": "req_resp_xyz789..."
    }
    ```
  </Accordion>
</AccordionGroup>

## Best Practices
1. Provide feedback regularly to improve routing decisions
2. Include detailed rationale for low scores
3. Store important translations for future analysis
4. Use consistent scoring criteria

## Common Issues
<AccordionGroup>
  <Accordion title="Invalid Score Range">
    Ensure scores are between 0 and 1
  </Accordion>
  <Accordion title="Missing Rationale">
    Always include explanatory rationale, especially for non-perfect scores
  </Accordion>
  <Accordion title="Request Format">
    Verify message format matches OpenAI chat completion format
  </Accordion>
</AccordionGroup>

## Next Steps
After implementing feedback:
1. Monitor router performance
2. Review feedback patterns
3. Track quality improvements
4. Analyze stored translations

<Note>
Remember to save response IDs for future reference. These can be useful for tracking improvements and analyzing patterns.
</Note>
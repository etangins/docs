---
title: 'Creating Judges'
description: 'Set up quality metrics for your router'
---
## Understanding Judges
Judges are the foundation of Martian's quality optimization system. They:
- Define what "good" means for your specific use case
- Automatically evaluate model outputs
- Guide router decisions for model selection
- Enable continuous quality improvement
<CardGroup cols={2}>
  <Card title="Quality Definition" icon="scale-balanced">
    Define custom quality metrics specific to your translation needs
  </Card>
  <Card title="Automatic Evaluation" icon="robot">
    Automatically score translations based on your criteria
  </Card>
</CardGroup>
## Creating a Translation Judge
Let's create a judge for Korean-English translation:

Start by creating a `create_judge.py` file.

With the following script you can change rubric, possible scores range, and also you can set generate_validation_plan to True to get more advanced judge.

```python create_judge.py

from config import API_URL, ORG_ID, HEADERS
import requests

url = f'{API_URL}/org/{ORG_ID}/judges'
data = {
    "name": "Translation Judge",
    "description": "A test judge for translation quality",
    "structure": "RubricNumericalJudge",
    "parameters": {
        "min_score": {"value": 0, "frozen": False},
        "max_score": {"value": 1, "frozen": False},
        "rubric": {"value": "Determine whether the translation is accurate and faithful to the original text.", "frozen": False},
        "judgeLLM": {"value": "openai/openai/gpt-4o-mini", "frozen": False},
    },
    "generate_validation_plan": False,
}
response = requests.post(url, headers=HEADERS, json=data)
print(response.json())

```

## Adding data to a judge

Start by creating a `add_data_to_judge.py` file.

With the following scripts you can change pass Request and Response data for judge validation, we provide you with examples that show you both positive and negative score. 

```python add_data_to_judge.py
import requests
from config import API_URL, ORG_ID, HEADERS, client

judge_id = input("Enter judge ID: ")
version_id = input("Enter version ID: ")

request = {
    "model": "gpt-4o-mini-2024-07-18",
    "messages": [
        {"role": "system", "content": """You are a highly skilled translator
             with expertise in many languages. Your task is to:
            - Identify if the input is Korean or English
            - If Korean, translate to English
            - If English, translate to Korean
            - Preserve meaning, tone, and nuance
            - Maintain proper grammar and formality level
            - output ONLY the translation
            """},
        {"role": "user", "content": "<translate>apple</translate>"}
    ],
}

response = client.chat.completions.create(
    model="gpt-4o-mini-2024-07-18",
    messages=[
        {"role": "system", "content": """You are a highly skilled translator with expertise in many languages. Your task is to:
            - Identify if the input is Korean or English
            - If Korean, translate to English
            - If English, translate to Korean
            - Preserve meaning, tone, and nuance
            - Maintain proper grammar and formality level
            - output ONLY the translation
            """},
        {"role": "user", "content": "<translate>apple</translate>"}
    ],
)

print(response)

# Convert the ChatCompletion object to a dictionary
response_dict = {
    'id': response.id,
    'choices': [
        {
            'message': {
                'role': choice.message.role,
                'content': choice.message.content
            },
            'index': choice.index,
            'finish_reason': choice.finish_reason
        }
        for choice in response.choices
    ],
    'model': response.model,
    'created': response.created,
    'usage': {
        'prompt_tokens': response.usage.prompt_tokens,
        'completion_tokens': response.usage.completion_tokens,
        'total_tokens': response.usage.total_tokens
    },
    'object': response.object,
    'cost': response.cost,
    'response': {
        'role': response.choices[0].message.role,
        'content': response.choices[0].message.content
    }
}

# Store response
url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}/versions/{version_id}/response'

data = {
    'request': request,
    'response': response_dict
}

response = requests.post(url, headers=HEADERS, json=data)
print(response.json()) 
```


# Store response
url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}/versions/{version_id}/response'

data = {
    'request': request,
    'response': response_dict
}

response = requests.post(url, headers=HEADERS, json=data)
print(response.json())
```

## Run the judge 

Now we are ready to get evaluations from the judge. After you create a script called `run_judge.py` go ahead and run the code below in that script.

```python run_judge.py
from config import API_URL, ORG_ID, HEADERS
import requests

def test_judge(judge_id, version_id, request_response_id):
    url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}/versions/{version_id}/call'
    
    # Example translation pair
    test_data = {
        'request_response_id': request_response_id,
    }
    
    response = requests.post(url, headers=HEADERS, json=test_data)
    result = response.json()
    print(result)


judge_id = input("Enter judge ID: ")
version_id = input("Enter version ID: ")
request_response_id = input("Enter request response ID: ")
test_judge(judge_id, version_id, request_response_id)
```

## Pass judgements to the judge

Start by creating a `add_judgement.py` file.

With the following script you can close the feedback loop and send judgements to the judge.

```python add_judgement.py
import requests
from config import API_URL, ORG_ID, HEADERS, client

judge_id = input("Enter judge ID: ")
version_id = input("Enter version ID: ")
request_response_id = input("Enter request_response_id: ")

judgement = {"score": 1, "rationale": "Very useful"}

url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}/versions/{version_id}/judgement'

data = {
    'request_response_id': request_response_id,
    'judgement': judgement
}

response = requests.post(url, headers=HEADERS, json=data)
print(response.json())
```

## Creating a new router using your judge

Once you feel confident with your judge you can create a new router with this judge. To update an existing router with your judge (see the next section).

Start by creating a `create_router_for_judge.py` file and add the following code.

```python create_router_for_judge.py
from config import API_URL, ORG_ID, HEADERS
import requests

judge_id = input("Enter judge ID: ")
judge_version_id = input("Enter judge version ID: ")

url = f'{API_URL}/org/{ORG_ID}/routers'

data = {
    'name': 'translation-router',
    'description': 'Routes Korean-English translation requests based on quality needs',
    'baseline_model': 'gpt-4o-mini',  # The model you currently use for the application
    'judge_id': judge_id,
    'judge_version_id': judge_version_id,
}

response = requests.post(url, headers=HEADERS, json=data)
print(response.json())
router_id = response.json()['router_id']
print(f"Created translation router with ID: {router_id}")
```

## Update existing router with judge

Start by creating a `update_router.py` file.

With the following script you can update an existing router to use the judge you created.

```python update_router.py
from config import API_URL, ORG_ID, HEADERS
import requests

router_id = input("Enter router ID: ")
router_version_id = input("Enter router version ID: ")
judge_id = input("Enter judge ID: ")
judge_version_id = input("Enter judge version ID: ")

url = f'{API_URL}/org/{ORG_ID}/routers/{router_id}/versions/{router_version_id}'

data = {
    'judge_id': judge_id,
    'judge_version_id': judge_version_id
}

response = requests.post(url, headers=HEADERS, json=data)
print(response.json())
router_id = response.json()['router_id']
print(f"Updated router with ID: {router_id}")
```

## View judge details

Start by creating a `view_judge.py` file.

With the following script you can get the details of the judge object.

```python view_judge.py
from config import API_URL, ORG_ID, HEADERS
import requests

judge_id = input("Enter judge ID: ")

url = f'{API_URL}/org/{ORG_ID}/judges/{judge_id}'
response = requests.get(url, headers=HEADERS)
details = response.json()
print(details)
```

## Best Practices
1. Test judge behavior with known good/bad translations
2. Monitor IAA scores across versions
3. Regularly review judge evaluations
4. Calibrate quality thresholds based on business needs
## Troubleshooting
<AccordionGroup>
  <Accordion title="Inconsistent Scores">
    Check IAA scores and review recent evaluations
  </Accordion>
  <Accordion title="Low Quality Scores">
    Review quality criteria and judge version
  </Accordion>
  <Accordion title="Integration Issues">
    Verify judge ID and version compatibility
  </Accordion>
</AccordionGroup>

<Note>
  Remember to periodically review judge versions to ensure they align with your current quality standards.
</Note>